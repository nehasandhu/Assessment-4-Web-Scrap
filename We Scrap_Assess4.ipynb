{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "566f6345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.support.select import Select\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# Importing selenium webdriver \n",
    "from selenium import webdriver\n",
    "\n",
    "# Importing required Exceptions which needs to handled\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "\n",
    "#Importing requests\n",
    "import requests\n",
    "\n",
    "# importing regex\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87119695",
   "metadata": {},
   "source": [
    "1. Scrape the details of most viewed videos on YouTube from Wikipedia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34c1c8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'E:\\DataTrained\\chromedriver.exe' #extracting path of the webdriver\n",
    "driver = webdriver.Chrome(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "b357206d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activating the chrome browser\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\"\n",
    "driver.get(url)\n",
    "time.sleep(3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e3ea54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "26034211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67 52 49 49 49\n"
     ]
    }
   ],
   "source": [
    "#Scraping Rank Data from the table\n",
    "RankT = driver.find_elements_by_xpath('//tbody/tr/td[1]')\n",
    "len(RankT)\n",
    "RankT[0:29]\n",
    "\n",
    "Rank=[]\n",
    "for i in RankT:\n",
    "    Rank.append(i.text)\n",
    "        \n",
    "Rank[0:30]\n",
    "\n",
    "\n",
    "\n",
    "#Scraping Name Data from the table\n",
    "NameT = driver.find_elements_by_xpath('//tbody/tr/td[2]')\n",
    "len(NameT)\n",
    "NameT\n",
    "\n",
    "Name=[]\n",
    "for i in NameT:\n",
    "    Name.append(i.text)\n",
    "        \n",
    "Name\n",
    "\n",
    "#Scraping Artist Data from the table\n",
    "ArtistT = driver.find_elements_by_xpath('//tbody/tr/td[3]')\n",
    "len(ArtistT)\n",
    "ArtistT\n",
    "\n",
    "Artist=[]\n",
    "for i in ArtistT:\n",
    "    Artist.append(i.text)\n",
    "        \n",
    "Artist\n",
    "\n",
    "#Scraping Views Data from the table\n",
    "ViewsT = driver.find_elements_by_xpath('//tbody/tr/td[4]')\n",
    "len(ViewsT)\n",
    "ViewsT\n",
    "\n",
    "views=[]\n",
    "for i in ViewsT:\n",
    "    views.append(i.text)\n",
    "        \n",
    "views\n",
    "\n",
    "#Scraping Views Data from the table\n",
    "UploadT = driver.find_elements_by_xpath('//tbody/tr/td[5]')\n",
    "len(UploadT)\n",
    "UploadT\n",
    "\n",
    "uploads=[]\n",
    "for i in UploadT:\n",
    "    uploads.append(i.text)\n",
    "        \n",
    "uploads\n",
    "\n",
    "print(len(Rank),len(Name),len(Artist),len(views),len(uploads))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "d89afd29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ranking</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist Name</th>\n",
       "      <th>Views</th>\n",
       "      <th>upload Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"[3]</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>6.31</td>\n",
       "      <td>October 8, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"[6]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>5.69</td>\n",
       "      <td>January 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[12]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>5.48</td>\n",
       "      <td>April 6, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Shape of You\"[13]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>5.27</td>\n",
       "      <td>May 2, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"See You Again\"[15]</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>4.58</td>\n",
       "      <td>March 6, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"Bath Song\"[20]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>4.56</td>\n",
       "      <td>February 27, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Phonics Song with Two Words\"[21]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>4.54</td>\n",
       "      <td>November 19, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[22]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>4.49</td>\n",
       "      <td>January 31, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Uptown Funk\"[23]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>4.40</td>\n",
       "      <td>July 15, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[24]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>3.96</td>\n",
       "      <td>May 24, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Gangnam Style\"[25]</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>3.92</td>\n",
       "      <td>April 5, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Wheels on the Bus\"[30]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.68</td>\n",
       "      <td>January 14, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Dame Tu Cosita\"[31]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.56</td>\n",
       "      <td>September 5, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Sugar\"[32]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>3.56</td>\n",
       "      <td>May 31, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Roar\"[33]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>3.54</td>\n",
       "      <td>October 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Counting Stars\"[34]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.44</td>\n",
       "      <td>October 7, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Sorry\"[35]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>3.32</td>\n",
       "      <td>June 16, 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Thinking Out Loud\"[36]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.28</td>\n",
       "      <td>May 31, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>\"Axel F\"[37]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>3.27</td>\n",
       "      <td>December 3, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Girls Like You\"[38]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.26</td>\n",
       "      <td>February 20, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Faded\"[39]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>3.21</td>\n",
       "      <td>July 25, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Dark Horse\"[40]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>3.21</td>\n",
       "      <td>June 25, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Let Her Go\"[41]</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>3.19</td>\n",
       "      <td>April 11, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Baa Baa Black Sheep\"[42]</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>3.19</td>\n",
       "      <td>March 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Bailando\"[43]</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>3.16</td>\n",
       "      <td>August 18, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Lean On\"[44]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.14</td>\n",
       "      <td>November 9, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Shake It Off\"[45]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>3.12</td>\n",
       "      <td>June 4, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Perfect\"[46]</td>\n",
       "      <td>J Balvin</td>\n",
       "      <td>3.07</td>\n",
       "      <td>June 29, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[47]</td>\n",
       "      <td>7,037,500,000</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>November 2, 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Mi Gente\"[48]</td>\n",
       "      <td>2,993,700,000</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>August 4, 2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ranking                                             Name  \\\n",
       "0       1.                            \"Baby Shark Dance\"[3]   \n",
       "1       2.                                   \"Despacito\"[6]   \n",
       "2       3.                       \"Johny Johny Yes Papa\"[12]   \n",
       "3       4.                               \"Shape of You\"[13]   \n",
       "4       5.                              \"See You Again\"[15]   \n",
       "5       6.                                  \"Bath Song\"[20]   \n",
       "6       7.                \"Phonics Song with Two Words\"[21]   \n",
       "7       8.  \"Learning Colors – Colorful Eggs on a Farm\"[22]   \n",
       "8       9.                                \"Uptown Funk\"[23]   \n",
       "9      10.   \"Masha and the Bear – Recipe for Disaster\"[24]   \n",
       "10     11.                              \"Gangnam Style\"[25]   \n",
       "11     12.                          \"Wheels on the Bus\"[30]   \n",
       "12     13.                             \"Dame Tu Cosita\"[31]   \n",
       "13     14.                                      \"Sugar\"[32]   \n",
       "14     15.                                       \"Roar\"[33]   \n",
       "15     16.                             \"Counting Stars\"[34]   \n",
       "16     17.                                      \"Sorry\"[35]   \n",
       "17     18.                          \"Thinking Out Loud\"[36]   \n",
       "18     19.                                     \"Axel F\"[37]   \n",
       "19     20.                             \"Girls Like You\"[38]   \n",
       "20     21.                                      \"Faded\"[39]   \n",
       "21     22.                                 \"Dark Horse\"[40]   \n",
       "22     23.                                 \"Let Her Go\"[41]   \n",
       "23     24.                        \"Baa Baa Black Sheep\"[42]   \n",
       "24     25.                                   \"Bailando\"[43]   \n",
       "25     26.                                    \"Lean On\"[44]   \n",
       "26     27.                               \"Shake It Off\"[45]   \n",
       "27     28.                                    \"Perfect\"[46]   \n",
       "28     29.           \"Waka Waka (This Time for Africa)\"[47]   \n",
       "29     30.                                   \"Mi Gente\"[48]   \n",
       "\n",
       "                   Artist Name             Views        upload Data  \n",
       "0                  LooLoo Kids              6.31    October 8, 2016  \n",
       "1                   Ed Sheeran              5.69   January 30, 2017  \n",
       "2                  Wiz Khalifa              5.48      April 6, 2015  \n",
       "3   Cocomelon – Nursery Rhymes              5.27        May 2, 2018  \n",
       "4                    ChuChu TV              4.58      March 6, 2014  \n",
       "5                  Miroshka TV              4.56  February 27, 2018  \n",
       "6                  Mark Ronson              4.54  November 19, 2014  \n",
       "7                   Get Movies              4.49   January 31, 2012  \n",
       "8                          Psy              4.40      July 15, 2012  \n",
       "9   Cocomelon – Nursery Rhymes              3.96       May 24, 2018  \n",
       "10                   El Chombo              3.92      April 5, 2018  \n",
       "11                    Maroon 5              3.68   January 14, 2015  \n",
       "12                  Katy Perry              3.56  September 5, 2013  \n",
       "13                 OneRepublic              3.56       May 31, 2013  \n",
       "14               Justin Bieber              3.54   October 22, 2015  \n",
       "15                  Ed Sheeran              3.44    October 7, 2014  \n",
       "16                  Crazy Frog              3.32      June 16, 2009  \n",
       "17                    Maroon 5              3.28       May 31, 2018  \n",
       "18                 Alan Walker              3.27   December 3, 2015  \n",
       "19                  Katy Perry              3.26  February 20, 2014  \n",
       "20                   Passenger              3.21      July 25, 2012  \n",
       "21  Cocomelon – Nursery Rhymes              3.21      June 25, 2018  \n",
       "22            Enrique Iglesias              3.19     April 11, 2014  \n",
       "23                 Major Lazer              3.19     March 22, 2015  \n",
       "24                Taylor Swift              3.16    August 18, 2014  \n",
       "25                  Ed Sheeran              3.14   November 9, 2017  \n",
       "26                     Shakira              3.12       June 4, 2010  \n",
       "27                    J Balvin              3.07      June 29, 2017  \n",
       "28               7,037,500,000     June 17, 2016   November 2, 2020  \n",
       "29               2,993,700,000  January 12, 2017     August 4, 2017  "
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF=pd.DataFrame({})\n",
    "DF['Ranking']=Rank[2:32]\n",
    "DF['Name']=Name[2:32]\n",
    "DF['Artist Name']=Artist[2:32]\n",
    "DF['Views']=views[2:32]\n",
    "DF['upload Data']=uploads[2:32]\n",
    "\n",
    "DF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f255e11b",
   "metadata": {},
   "source": [
    "2. Scrape the details team India’s international fixtures from bcci.tv.\n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Match title (I.e. 1st ODI)\n",
    "B) Series\n",
    "C) Place\n",
    "D) Date\n",
    "E) Time\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "8d286a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activating the chrome browser\n",
    "url = \"https://www.bcci.tv/\"\n",
    "driver.get(url)\n",
    "time.sleep(3)\n",
    "\n",
    "# Asking the user to input the keywords he/she wants to search\n",
    "#user_inp = input('Enter the product you want to search : ')\n",
    "\n",
    "#Make empty lists\n",
    "Matchtitle = []   \n",
    "Series = []\n",
    "Place = []\n",
    "Date = []\n",
    "Time = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56b3c36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "2e97660f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match Name</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022</td>\n",
       "      <td>SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022</td>\n",
       "      <td>Arun Jaitley Stadium,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022</td>\n",
       "      <td>SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022</td>\n",
       "      <td>Barabati Stadium,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022</td>\n",
       "      <td>SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022</td>\n",
       "      <td>Dr YS Rajasekhara Reddy ACA-VDCA Cricket Stadium,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022</td>\n",
       "      <td>SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022</td>\n",
       "      <td>Saurashtra Cricket Association Stadium,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022</td>\n",
       "      <td>SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022</td>\n",
       "      <td>M Chinnaswamy Stadium,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>--</td>\n",
       "      <td></td>\n",
       "      <td>----</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>--</td>\n",
       "      <td></td>\n",
       "      <td>----</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>--</td>\n",
       "      <td></td>\n",
       "      <td>----</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>--</td>\n",
       "      <td></td>\n",
       "      <td>----</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>--</td>\n",
       "      <td></td>\n",
       "      <td>----</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Match Name  \\\n",
       "0  SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022   \n",
       "1  SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022   \n",
       "2  SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022   \n",
       "3  SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022   \n",
       "4  SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022   \n",
       "5                                          --   \n",
       "6                                          --   \n",
       "7                                          --   \n",
       "8                                          --   \n",
       "9                                          --   \n",
       "\n",
       "                                       Series  \\\n",
       "0  SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022   \n",
       "1  SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022   \n",
       "2  SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022   \n",
       "3  SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022   \n",
       "4  SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022   \n",
       "5                                               \n",
       "6                                               \n",
       "7                                               \n",
       "8                                               \n",
       "9                                               \n",
       "\n",
       "                                               Place  \n",
       "0                              Arun Jaitley Stadium,  \n",
       "1                                  Barabati Stadium,  \n",
       "2  Dr YS Rajasekhara Reddy ACA-VDCA Cricket Stadium,  \n",
       "3            Saurashtra Cricket Association Stadium,  \n",
       "4                             M Chinnaswamy Stadium,  \n",
       "5                                               ----  \n",
       "6                                               ----  \n",
       "7                                               ----  \n",
       "8                                               ----  \n",
       "9                                               ----  "
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scrape Matchtitle\n",
    "MatchT = driver.find_elements_by_xpath('//span[@class=\"ng-binding\"]')\n",
    "len(MatchT)\n",
    "MatchT\n",
    "\n",
    "Matchtitle=[]\n",
    "for i in MatchT:\n",
    "    if i.text is '':\n",
    "        Matchtitle.append(\"--\") \n",
    "    else:\n",
    "        Matchtitle.append(i.text)\n",
    "        \n",
    "Matchtitle\n",
    "\n",
    "#scrape Series\n",
    "Ser = driver.find_elements_by_xpath('//span[@class=\"ng-binding\"]')\n",
    "len(Ser)\n",
    "Ser\n",
    "\n",
    "Series=[]\n",
    "for i in Ser:\n",
    "    if i.text is '':\n",
    "        Series.append(i.text) \n",
    "    else:\n",
    "        Series.append(i.text)\n",
    "        \n",
    "Series\n",
    "\n",
    "\n",
    "#scrape Place\n",
    "Pl = driver.find_elements_by_xpath('//span[@class=\"ng-binding ng-scope\"]')\n",
    "len(Pl)\n",
    "Pl\n",
    "\n",
    "Place=[]\n",
    "for i in Pl:\n",
    "    if i.text is '':\n",
    "        Place.append('----') \n",
    "    else:\n",
    "        Place.append(i.text)\n",
    "        \n",
    "Place\n",
    "\n",
    "# creating the dataframe from the scraped data and taking only first 10 data\n",
    "df=pd.DataFrame({\"Match Name\":Matchtitle[0:10],\"Series\":Series[0:10],\"Place\":Place[0:10]\n",
    "                })\n",
    "df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d61599e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f450782",
   "metadata": {},
   "source": [
    "3. Scrape the details of selenium exception from guru99.com.\n",
    "Url = https://www.guru99.com/\n",
    "You need to find following details:\n",
    "A) Name\n",
    "B) Description\n",
    "Note: - From guru99 home page you have to reach to selenium exception handling page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d9e6ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activating the chrome browser\n",
    "try:\n",
    "    url = \"https://www.guru99.com//\"\n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "    \n",
    "except NoSuchElementException :\n",
    "    print(\"No Login page\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212972e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d866541d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['➤ Web Development\\n➤ Online Courses\\n➤ Reviews\\n➤ Excel Tutorials\\n➤ Accounting\\n➤ Ethical Hacking\\n➤ Cloud Computing\\n➤ Photoshop CC\\n➤ Business Analyst\\n➤ Informatica\\n➤ Project Management\\n➤ VBA\\n➤ CCNA\\n➤ Jenkins\\n➤ Software Engineering\\n➤ Blockchain\\n➤ Cloud Mining Sites\\n➤ Go Programming\\n➤ Networking\\n➤ Operating System\\n➤ Compiler Design\\n➤ COBOL\\n➤ Embedded Systems\\n➤ Algorithms\\n➤ Salesforce\\n➤ eCommerce Platforms\\n➤ Website Monitoring Tools\\n➤ IP Blocker Apps\\n➤ Best VPNs\\n➤ VPN for iPhone']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scrape Place\n",
    "name = driver.find_elements_by_xpath('/html/body/div[1]/div/div/div/main/div/article/div/div[1]/div[2]/div[1]/div/ul[1]')\n",
    "name2 = driver.find_elements_by_xpath('/html/body/div[1]/div/div/div/main/div/article/div/div[1]/div[2]/div[2]/div/ul[1]')\n",
    "name3 = driver.find_elements_by_xpath('/html/body/div[1]/div/div/div/main/div/article/div/div[1]/div[2]/div[3]/div/ul[1]')\n",
    "name4 = driver.find_elements_by_xpath('/html/body/div[1]/div/div/div/main/div/article/div/div[1]/div[2]/div[4]/div/ul[1]')\n",
    "name5 = driver.find_elements_by_xpath('/html/body')\n",
    "\n",
    "\n",
    "\n",
    "name\n",
    "name2\n",
    "name3                                     \n",
    "name4\n",
    "name5\n",
    "                                      \n",
    "CourseName=[]\n",
    "for i in name:\n",
    "    if i.text is '':\n",
    "        CourseName.append('----') \n",
    "    else:\n",
    "        CourseName.append(i.text)\n",
    "        \n",
    "CourseName\n",
    "\n",
    "CourseName2=[]\n",
    "for i in name2:\n",
    "    if i.text is '':\n",
    "        CourseName2.append('----') \n",
    "    else:\n",
    "        CourseName2.append(i.text)\n",
    "        \n",
    "CourseName2\n",
    "                                      \n",
    "\n",
    "CourseName3=[]\n",
    "for i in name3:\n",
    "    if i.text is '':\n",
    "        CourseName3.append('----') \n",
    "    else:\n",
    "        CourseName3.append(i.text)\n",
    "        \n",
    "\n",
    "CourseName3\n",
    "                                      \n",
    "CourseName4=[]\n",
    "for i in name4:\n",
    "    if i.text is '':\n",
    "        CourseName4.append('----') \n",
    "    else:\n",
    "        CourseName4.append(i.text)\n",
    "        \n",
    "CourseName4\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e7647919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Course-Name</th>\n",
       "      <th>Course-Name2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>➤ Software Testing\\n➤ QTP (Quick Test Professi...</td>\n",
       "      <td>➤ SAP Beginner\\n➤ SAP ABAP\\n➤ SAP HR/HCM\\n➤ SA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Course-Name  \\\n",
       "0  ➤ Software Testing\\n➤ QTP (Quick Test Professi...   \n",
       "\n",
       "                                        Course-Name2  \n",
       "0  ➤ SAP Beginner\\n➤ SAP ABAP\\n➤ SAP HR/HCM\\n➤ SA...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df= pd.DataFrame({'Course-Name': CourseName,'Course-Name2': CourseName2})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "67997a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Course-Name</th>\n",
       "      <th>Course-Name2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>➤ Software Testing</td>\n",
       "      <td>➤ SAP Beginner\\n➤ SAP ABAP\\n➤ SAP HR/HCM\\n➤ SA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>➤ QTP (Quick Test Professional)</td>\n",
       "      <td>➤ SAP Beginner\\n➤ SAP ABAP\\n➤ SAP HR/HCM\\n➤ SA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>➤ Selenium</td>\n",
       "      <td>➤ SAP Beginner\\n➤ SAP ABAP\\n➤ SAP HR/HCM\\n➤ SA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>➤ Mobile App Testing</td>\n",
       "      <td>➤ SAP Beginner\\n➤ SAP ABAP\\n➤ SAP HR/HCM\\n➤ SA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>➤ Cucumber Testing</td>\n",
       "      <td>➤ SAP Beginner\\n➤ SAP ABAP\\n➤ SAP HR/HCM\\n➤ SA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>➤ SoapUI</td>\n",
       "      <td>➤ SAP Beginner\\n➤ SAP ABAP\\n➤ SAP HR/HCM\\n➤ SA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>➤ Agile Testing</td>\n",
       "      <td>➤ SAP Beginner\\n➤ SAP ABAP\\n➤ SAP HR/HCM\\n➤ SA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>➤ JUnit</td>\n",
       "      <td>➤ SAP Beginner\\n➤ SAP ABAP\\n➤ SAP HR/HCM\\n➤ SA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>➤ RPA</td>\n",
       "      <td>➤ SAP Beginner\\n➤ SAP ABAP\\n➤ SAP HR/HCM\\n➤ SA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Course-Name  \\\n",
       "0               ➤ Software Testing   \n",
       "0  ➤ QTP (Quick Test Professional)   \n",
       "0                       ➤ Selenium   \n",
       "0             ➤ Mobile App Testing   \n",
       "0               ➤ Cucumber Testing   \n",
       "0                         ➤ SoapUI   \n",
       "0                  ➤ Agile Testing   \n",
       "0                          ➤ JUnit   \n",
       "0                            ➤ RPA   \n",
       "\n",
       "                                        Course-Name2  \n",
       "0  ➤ SAP Beginner\\n➤ SAP ABAP\\n➤ SAP HR/HCM\\n➤ SA...  \n",
       "0  ➤ SAP Beginner\\n➤ SAP ABAP\\n➤ SAP HR/HCM\\n➤ SA...  \n",
       "0  ➤ SAP Beginner\\n➤ SAP ABAP\\n➤ SAP HR/HCM\\n➤ SA...  \n",
       "0  ➤ SAP Beginner\\n➤ SAP ABAP\\n➤ SAP HR/HCM\\n➤ SA...  \n",
       "0  ➤ SAP Beginner\\n➤ SAP ABAP\\n➤ SAP HR/HCM\\n➤ SA...  \n",
       "0  ➤ SAP Beginner\\n➤ SAP ABAP\\n➤ SAP HR/HCM\\n➤ SA...  \n",
       "0  ➤ SAP Beginner\\n➤ SAP ABAP\\n➤ SAP HR/HCM\\n➤ SA...  \n",
       "0  ➤ SAP Beginner\\n➤ SAP ABAP\\n➤ SAP HR/HCM\\n➤ SA...  \n",
       "0  ➤ SAP Beginner\\n➤ SAP ABAP\\n➤ SAP HR/HCM\\n➤ SA...  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Course-Name'].str.split('\\n', expand=True).stack().reset_index(level=0).set_index('level_0').rename(columns={0:'Course-Name'}).join(df.drop('Course-Name', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c27b96ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Course-Name2</th>\n",
       "      <th>Course-Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>➤ SAP Beginner</td>\n",
       "      <td>➤ Software Testing\\n➤ QTP (Quick Test Professi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>➤ SAP ABAP</td>\n",
       "      <td>➤ Software Testing\\n➤ QTP (Quick Test Professi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>➤ SAP HR/HCM</td>\n",
       "      <td>➤ Software Testing\\n➤ QTP (Quick Test Professi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>➤ SAP FICO</td>\n",
       "      <td>➤ Software Testing\\n➤ QTP (Quick Test Professi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>➤ SAP Basis</td>\n",
       "      <td>➤ Software Testing\\n➤ QTP (Quick Test Professi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>➤ SAP SD</td>\n",
       "      <td>➤ Software Testing\\n➤ QTP (Quick Test Professi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>➤ SAP CRM</td>\n",
       "      <td>➤ Software Testing\\n➤ QTP (Quick Test Professi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>➤ SAP MM</td>\n",
       "      <td>➤ Software Testing\\n➤ QTP (Quick Test Professi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>➤ SAP CO</td>\n",
       "      <td>➤ Software Testing\\n➤ QTP (Quick Test Professi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>➤ SAP Payroll</td>\n",
       "      <td>➤ Software Testing\\n➤ QTP (Quick Test Professi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>➤ SAP BI/BW</td>\n",
       "      <td>➤ Software Testing\\n➤ QTP (Quick Test Professi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>➤ SAP PP</td>\n",
       "      <td>➤ Software Testing\\n➤ QTP (Quick Test Professi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>➤ SAP QM</td>\n",
       "      <td>➤ Software Testing\\n➤ QTP (Quick Test Professi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>➤ SAP HANA</td>\n",
       "      <td>➤ Software Testing\\n➤ QTP (Quick Test Professi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>➤ Crystal Reports</td>\n",
       "      <td>➤ Software Testing\\n➤ QTP (Quick Test Professi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>➤ SAP PI/PO</td>\n",
       "      <td>➤ Software Testing\\n➤ QTP (Quick Test Professi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>➤ SAPUI5</td>\n",
       "      <td>➤ Software Testing\\n➤ QTP (Quick Test Professi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>➤ SAP Security</td>\n",
       "      <td>➤ Software Testing\\n➤ QTP (Quick Test Professi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>➤ SAP BPC</td>\n",
       "      <td>➤ Software Testing\\n➤ QTP (Quick Test Professi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>➤ SAP BODS</td>\n",
       "      <td>➤ Software Testing\\n➤ QTP (Quick Test Professi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Course-Name2                                        Course-Name\n",
       "0     ➤ SAP Beginner  ➤ Software Testing\\n➤ QTP (Quick Test Professi...\n",
       "0         ➤ SAP ABAP  ➤ Software Testing\\n➤ QTP (Quick Test Professi...\n",
       "0       ➤ SAP HR/HCM  ➤ Software Testing\\n➤ QTP (Quick Test Professi...\n",
       "0         ➤ SAP FICO  ➤ Software Testing\\n➤ QTP (Quick Test Professi...\n",
       "0        ➤ SAP Basis  ➤ Software Testing\\n➤ QTP (Quick Test Professi...\n",
       "0           ➤ SAP SD  ➤ Software Testing\\n➤ QTP (Quick Test Professi...\n",
       "0          ➤ SAP CRM  ➤ Software Testing\\n➤ QTP (Quick Test Professi...\n",
       "0           ➤ SAP MM  ➤ Software Testing\\n➤ QTP (Quick Test Professi...\n",
       "0           ➤ SAP CO  ➤ Software Testing\\n➤ QTP (Quick Test Professi...\n",
       "0      ➤ SAP Payroll  ➤ Software Testing\\n➤ QTP (Quick Test Professi...\n",
       "0        ➤ SAP BI/BW  ➤ Software Testing\\n➤ QTP (Quick Test Professi...\n",
       "0           ➤ SAP PP  ➤ Software Testing\\n➤ QTP (Quick Test Professi...\n",
       "0           ➤ SAP QM  ➤ Software Testing\\n➤ QTP (Quick Test Professi...\n",
       "0         ➤ SAP HANA  ➤ Software Testing\\n➤ QTP (Quick Test Professi...\n",
       "0  ➤ Crystal Reports  ➤ Software Testing\\n➤ QTP (Quick Test Professi...\n",
       "0        ➤ SAP PI/PO  ➤ Software Testing\\n➤ QTP (Quick Test Professi...\n",
       "0           ➤ SAPUI5  ➤ Software Testing\\n➤ QTP (Quick Test Professi...\n",
       "0     ➤ SAP Security  ➤ Software Testing\\n➤ QTP (Quick Test Professi...\n",
       "0          ➤ SAP BPC  ➤ Software Testing\\n➤ QTP (Quick Test Professi...\n",
       "0         ➤ SAP BODS  ➤ Software Testing\\n➤ QTP (Quick Test Professi..."
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Course-Name2'].str.split('\\n', expand=True).stack().reset_index(level=0).set_index('level_0').rename(columns={0:'Course-Name2'}).join(df.drop('Course-Name2', axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f75665",
   "metadata": {},
   "source": [
    "4. Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details:\n",
    "A) Rank\n",
    "B) State\n",
    "C) GSDP(18-19)\n",
    "D) GSDP(17-18)\n",
    "E) Share(2017)\n",
    "F) GDP($ billion)\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f1773b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'NoSuchElementException' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9944/2057885835.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"https://www.statisticstimes.com/economy/india/indian-states-gdp-growth.php\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'driver' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9944/2057885835.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mexcept\u001b[0m \u001b[0mNoSuchElementException\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No Login page\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'NoSuchElementException' is not defined"
     ]
    }
   ],
   "source": [
    "# Activating the chrome browser\n",
    "try:\n",
    "    url = \"https://www.statisticstimes.com/economy/india/indian-states-gdp-growth.php\"\n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "    \n",
    "except NoSuchElementException :\n",
    "    print(\"No Login page\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "2189b59e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"aa9af8abe0a936ece3de1c1c00dcd5cf\", element=\"29b0e0da-ee1a-49a6-88af-af239a09acce\")>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "India_search=driver.find_element_by_xpath('/html/body/div[2]/div[1]/div[2]/div[2]/div/a[3]')\n",
    "India_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5580cfa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "ffb878cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['12.56',\n",
       " '9.94',\n",
       " '9.83',\n",
       " '8.79',\n",
       " '8.64',\n",
       " '8.04',\n",
       " '7.96',\n",
       " '7.72',\n",
       " '7.66',\n",
       " '7.54',\n",
       " '7.50',\n",
       " '7.36',\n",
       " '7.34',\n",
       " '7.32',\n",
       " '7.14',\n",
       " '7.12',\n",
       " '6.88',\n",
       " '6.54',\n",
       " '6.51',\n",
       " '6.34',\n",
       " '6.18',\n",
       " '6.17',\n",
       " '6.04',\n",
       " '5.96',\n",
       " '5.88',\n",
       " '5.61',\n",
       " '5.51',\n",
       " '5.48',\n",
       " '5.46',\n",
       " '5.16']"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scraping Rank Data from the table\n",
    "RankGSDB = driver.find_elements_by_xpath('/html/body/div[3]/div[2]/div[5]/div[1]/div/table/tbody/tr/td[1]')\n",
    "len(RankGSDB)\n",
    "RankGSDB\n",
    "\n",
    "Rank=[]\n",
    "for i in RankGSDB:\n",
    "    Rank.append(i.text)\n",
    "        \n",
    "Rank[0:30]\n",
    "\n",
    "#Scraping State Data from the table\n",
    "StateGSDB = driver.find_elements_by_xpath('/html/body/div[3]/div[2]/div[5]/div[1]/div/table/tbody/tr/td[2]')\n",
    "len(StateGSDB)\n",
    "StateGSDB\n",
    "\n",
    "State=[]\n",
    "for i in StateGSDB:\n",
    "    State.append(i.text)\n",
    "        \n",
    "State[0:30]\n",
    "\n",
    "\n",
    "#Scraping GSDB18-19 Data from the table\n",
    "GSDB18_19 = driver.find_elements_by_xpath('/html/body/div[3]/div[2]/div[5]/div[1]/div/table/tbody/tr/td[4]')\n",
    "len(GSDB18_19)\n",
    "GSDB18_19\n",
    "\n",
    "G1819=[]\n",
    "for i in GSDB18_19:\n",
    "    G1819.append(i.text)\n",
    "        \n",
    "G1819[0:30]\n",
    "\n",
    "#Scraping GSDB17-18 Data from the table\n",
    "GSDB17_18 = driver.find_elements_by_xpath('/html/body/div[3]/div[2]/div[5]/div[1]/div/table/tbody/tr/td[4]')\n",
    "len(GSDB17_18)\n",
    "GSDB17_18\n",
    "\n",
    "G1718=[]\n",
    "for i in GSDB17_18:\n",
    "    G1718.append(i.text)\n",
    "        \n",
    "G1718[0:30]\n",
    "\n",
    "#Scraping Share17 Data from the table\n",
    "Share17 = driver.find_elements_by_xpath('/html/body/div[3]/div[2]/div[5]/div[1]/div/table/tbody/tr/td[5]')\n",
    "len(Share17)\n",
    "Share17\n",
    "\n",
    "share=[]\n",
    "for i in Share17:\n",
    "    share.append(i.text)\n",
    "        \n",
    "share[0:30]\n",
    "\n",
    "#Scraping Average current price and its dollar rate Data from the table\n",
    "Average = driver.find_elements_by_xpath('/html/body/div[3]/div[2]/div[5]/div[1]/div/table/tbody/tr/td[6]')\n",
    "len(Average)\n",
    "Average\n",
    "\n",
    "Avg=[]\n",
    "for i in Averagee17:\n",
    "    Avg.append(i.text)\n",
    "        \n",
    "Avg[0:30]\n",
    "\n",
    "\n",
    "\n",
    "/html/body/div[3]/div[2]/div[5]/div[1]/div/table/tbody/tr[4]/td[6]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "23f7d517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['18.91',\n",
       " '12.32',\n",
       " '-',\n",
       " '9.30',\n",
       " '13.27',\n",
       " '10.48',\n",
       " '12.61',\n",
       " '13.13',\n",
       " '-',\n",
       " '-',\n",
       " '11.99',\n",
       " '12.73',\n",
       " '-',\n",
       " '6.86',\n",
       " '7.56',\n",
       " '13.23',\n",
       " '-',\n",
       " '8.32',\n",
       " '6.50',\n",
       " '-',\n",
       " '15.36',\n",
       " '-',\n",
       " '10.56',\n",
       " '14.07',\n",
       " '9.19',\n",
       " '8.26',\n",
       " '-',\n",
       " '9.95',\n",
       " '-',\n",
       " '15.04',\n",
       " '11.09',\n",
       " '9.23',\n",
       " '-']"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scraping Average current price and its dollar rate Data from the table\n",
    "Average = driver.find_elements_by_xpath('/html/body/div[3]/div[2]/div[5]/div[1]/div/table/tbody/tr/td[6]')\n",
    "len(Average)\n",
    "Average\n",
    "\n",
    "Avg=[]\n",
    "AvgDollar = []\n",
    "for i in Average:\n",
    "    Avg.append(i.text)\n",
    "        \n",
    "\n",
    "Avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "d9420735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP(18-19)</th>\n",
       "      <th>GSDP(17-18)</th>\n",
       "      <th>Share(2017)</th>\n",
       "      <th>GDP($ billion)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>11.63</td>\n",
       "      <td>11.63</td>\n",
       "      <td>12.56</td>\n",
       "      <td>18.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>11.69</td>\n",
       "      <td>11.69</td>\n",
       "      <td>9.94</td>\n",
       "      <td>12.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>9.19</td>\n",
       "      <td>9.19</td>\n",
       "      <td>9.83</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>6.67</td>\n",
       "      <td>6.67</td>\n",
       "      <td>8.79</td>\n",
       "      <td>9.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>7.49</td>\n",
       "      <td>7.49</td>\n",
       "      <td>8.64</td>\n",
       "      <td>13.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>7.71</td>\n",
       "      <td>7.71</td>\n",
       "      <td>8.04</td>\n",
       "      <td>10.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>9.53</td>\n",
       "      <td>9.53</td>\n",
       "      <td>7.96</td>\n",
       "      <td>12.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>5.94</td>\n",
       "      <td>5.94</td>\n",
       "      <td>7.72</td>\n",
       "      <td>13.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>6.87</td>\n",
       "      <td>6.87</td>\n",
       "      <td>7.66</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>7.39</td>\n",
       "      <td>7.39</td>\n",
       "      <td>7.54</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>5.77</td>\n",
       "      <td>5.77</td>\n",
       "      <td>7.50</td>\n",
       "      <td>11.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>4.45</td>\n",
       "      <td>4.45</td>\n",
       "      <td>7.36</td>\n",
       "      <td>12.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Assam</td>\n",
       "      <td>6.42</td>\n",
       "      <td>6.42</td>\n",
       "      <td>7.34</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>4.23</td>\n",
       "      <td>4.23</td>\n",
       "      <td>7.32</td>\n",
       "      <td>6.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>7.10</td>\n",
       "      <td>7.10</td>\n",
       "      <td>7.14</td>\n",
       "      <td>7.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>7.95</td>\n",
       "      <td>7.95</td>\n",
       "      <td>7.12</td>\n",
       "      <td>13.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>5.99</td>\n",
       "      <td>5.99</td>\n",
       "      <td>6.88</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>6.97</td>\n",
       "      <td>6.97</td>\n",
       "      <td>6.54</td>\n",
       "      <td>8.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>6.26</td>\n",
       "      <td>6.26</td>\n",
       "      <td>6.51</td>\n",
       "      <td>6.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>7.46</td>\n",
       "      <td>7.46</td>\n",
       "      <td>6.34</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>9.27</td>\n",
       "      <td>9.27</td>\n",
       "      <td>6.18</td>\n",
       "      <td>15.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>4.59</td>\n",
       "      <td>4.59</td>\n",
       "      <td>6.17</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>6.84</td>\n",
       "      <td>6.84</td>\n",
       "      <td>6.04</td>\n",
       "      <td>10.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>2.93</td>\n",
       "      <td>2.93</td>\n",
       "      <td>5.96</td>\n",
       "      <td>14.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>5.98</td>\n",
       "      <td>5.98</td>\n",
       "      <td>5.88</td>\n",
       "      <td>9.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>7.06</td>\n",
       "      <td>7.06</td>\n",
       "      <td>5.61</td>\n",
       "      <td>8.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>6.08</td>\n",
       "      <td>6.08</td>\n",
       "      <td>5.51</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Goa</td>\n",
       "      <td>9.75</td>\n",
       "      <td>9.75</td>\n",
       "      <td>5.48</td>\n",
       "      <td>9.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>7.05</td>\n",
       "      <td>7.05</td>\n",
       "      <td>5.46</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>6.41</td>\n",
       "      <td>6.41</td>\n",
       "      <td>5.16</td>\n",
       "      <td>15.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank              State GSDP(18-19) GSDP(17-18) Share(2017) GDP($ billion)\n",
       "0     1            Mizoram       11.63       11.63       12.56          18.91\n",
       "1     2            Tripura       11.69       11.69        9.94          12.32\n",
       "2     3            Gujarat        9.19        9.19        9.83              -\n",
       "3     4          Karnataka        6.67        6.67        8.79           9.30\n",
       "4     5            Haryana        7.49        7.49        8.64          13.27\n",
       "5     6              Delhi        7.71        7.71        8.04          10.48\n",
       "6     7          Telangana        9.53        9.53        7.96          12.61\n",
       "7     8             Sikkim        5.94        5.94        7.72          13.13\n",
       "8     9        Uttarakhand        6.87        6.87        7.66              -\n",
       "9    10         Chandigarh        7.39        7.39        7.54              -\n",
       "10   11     Madhya Pradesh        5.77        5.77        7.50          11.99\n",
       "11   12     Andhra Pradesh        4.45        4.45        7.36          12.73\n",
       "12   13              Assam        6.42        6.42        7.34              -\n",
       "13   14             Odisha        4.23        4.23        7.32           6.86\n",
       "14   15   Himachal Pradesh        7.10        7.10        7.14           7.56\n",
       "15   16         Tamil Nadu        7.95        7.95        7.12          13.23\n",
       "16   17        Maharashtra        5.99        5.99        6.88              -\n",
       "17   18          Rajasthan        6.97        6.97        6.54           8.32\n",
       "18   19      Uttar Pradesh        6.26        6.26        6.51           6.50\n",
       "19   20             Kerala        7.46        7.46        6.34              -\n",
       "20   21              Bihar        9.27        9.27        6.18          15.36\n",
       "21   22  Arunachal Pradesh        4.59        4.59        6.17              -\n",
       "22   23          Jharkhand        6.84        6.84        6.04          10.56\n",
       "23   24            Manipur        2.93        2.93        5.96          14.07\n",
       "24   25             Punjab        5.98        5.98        5.88           9.19\n",
       "25   26       Chhattisgarh        7.06        7.06        5.61           8.26\n",
       "26   27    Jammu & Kashmir        6.08        6.08        5.51              -\n",
       "27   28                Goa        9.75        9.75        5.48           9.95\n",
       "28   29           Nagaland        7.05        7.05        5.46              -\n",
       "29   30        West Bengal        6.41        6.41        5.16          15.04"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Creating a dataframe\n",
    "df=pd.DataFrame({})\n",
    "df['Rank']=Rank[0:30]\n",
    "df['State']=State[0:30]\n",
    "df['GSDP(18-19)']=G1819[0:30]\n",
    "df['GSDP(17-18)']=G1718[0:30]\n",
    "df['Share(2017)']=share[0:30]\n",
    "df['GDP($ billion)']=Avg[0:30]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003f6904",
   "metadata": {},
   "source": [
    "5. Scrape the details of trending repositories on Github.com.\n",
    "Url = https://github.com/\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used\n",
    "ASSIGNMENT\n",
    "Note: - From the home page you have to click on the trending option from Explore menu through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6e761fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activating the chrome browser\n",
    "\n",
    "PATH = 'E:\\DataTrained\\chromedriver.exe' #extracting path of the webdriver\n",
    "driver = webdriver.Chrome(PATH)\n",
    "try:\n",
    "    url = \"https://github.com/trending\"\n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "    \n",
    "except NoSuchElementException :\n",
    "    print(\"No Login page\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2310e286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This repository provides motion datasets collected by Bandai Namco Research Inc',\n",
       " 'The core software distribution for the Inform 7 programming language.',\n",
       " 'Open Source real-time strategy game engine for early Westwood games such as Command & Conquer: Red Alert written in C# using SDL and OpenGL. Runs on Windows, Linux, *BSD and Mac OS X.',\n",
       " 'PowerShell for every system!',\n",
       " '模拟手写效果，节约时间。',\n",
       " '🏆 A ranked list of awesome machine learning Python libraries. Updated weekly.',\n",
       " 'Spacedrive is an open source cross-platform file explorer, powered by a virtual distributed filesystem written in Rust.',\n",
       " 'A rule-based tunnel in Go.',\n",
       " 'RisingWave: the next-generation streaming database in the cloud.',\n",
       " 'JSON Hero is an open-source, beautiful JSON explorer for the web that lets you browse, search and navigate your JSON files at speed. 🚀',\n",
       " 'Papers from the computer science community to read and discuss.',\n",
       " 'Translate your TypeScript errors into plain English',\n",
       " '🐢 Magical shell history',\n",
       " 'The Optimism monorepo',\n",
       " 'Make stream processing easier! Flink & Spark development scaffold, The original intention of StreamX is to make the development of Flink easier. StreamX focuses on the management of development phases and tasks. Our ultimate goal is to build a one-stop big data solution integrating stream processing, batch processing, data warehouse and data laker.',\n",
       " 'Main repository for the Core WCF project',\n",
       " '收集整理 GitHub 上高质量、有趣的开源项目。',\n",
       " 'Pilot – mini game engine for games104',\n",
       " '分享 GitHub 上有趣、入门级的开源项目。Share interesting, entry-level open source projects on GitHub.',\n",
       " 'Apache Flink',\n",
       " 'Optimized Go Compression Packages',\n",
       " 'KEDA is a Kubernetes-based Event Driven Autoscaling component. It provides event driven scale for any container running in Kubernetes',\n",
       " 'Top2Vec learns jointly embedded topic, document and word vectors.',\n",
       " 'Wireit upgrades your npm scripts to make them smarter and more efficient.']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping Repository Names\n",
    "RepName = driver.find_elements_by_xpath('/html/body/div[4]/main/div[3]/div/div[2]/article/h1')\n",
    "len(RepName)\n",
    "\n",
    "RName=[]\n",
    "for i in RepName:\n",
    "    RName.append(i.text)\n",
    "        \n",
    "RName[0:24]\n",
    "\n",
    "# Scraping Repository description\n",
    "RepDisc = driver.find_elements_by_xpath('/html/body/div[4]/main/div[3]/div/div[2]/article/p')\n",
    "len(RepDisc)\n",
    "\n",
    "RDisc=[]\n",
    "for i in RepDisc:\n",
    "    RDisc.append(i.text)\n",
    "        \n",
    "RDisc[0:24]   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fca178bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PowerShell for every system!',\n",
       " '科技爱好者周刊，每周五发布',\n",
       " 'The modern web developer’s platform',\n",
       " 'Your self-hosted, globally interconnected microblogging community',\n",
       " 'Spacedrive is an open source cross-platform file explorer, powered by a virtual distributed filesystem written in Rust.',\n",
       " '🏆 A ranked list of awesome machine learning Python libraries. Updated weekly.',\n",
       " 'JSON Hero is an open-source, beautiful JSON explorer for the web that lets you browse, search and navigate your JSON files at speed. 🚀',\n",
       " 'Create UIs for your machine learning model in Python in 3 minutes',\n",
       " 'Low code project to build admin panels, internal tools, and dashboards. Integrates with 15+ databases and any API.',\n",
       " 'Wireit upgrades your npm scripts to make them smarter and more efficient.',\n",
       " 'FE 기술 소식 큐레이션 뉴스레터',\n",
       " '润学全球官方指定GITHUB，整理润学宗旨、纲领、理论和各类润之实例；解决为什么润，润去哪里，怎么润三大问题； 并成为新中国人的核心宗教，核心信念。',\n",
       " 'A multi-voice TTS system trained with an emphasis on quality',\n",
       " 'RF transmitter for Raspberry Pi',\n",
       " 'Constraint-based geometry sketcher for blender',\n",
       " '模拟手写效果，节约时间。',\n",
       " 'HFS is a file server offering a virtual file system (vfs). You can easily share a single file instead of the whole folder, or you can rename it, but without touching the real file, just virtually.',\n",
       " 'Complete container management platform',\n",
       " 'A complete computer science study plan to become a software engineer.',\n",
       " 'A drop-in javascript spreadsheet library that provides rich features like Excel and Google Sheets',\n",
       " 'RedisInsight',\n",
       " 'Terraform module to create an Elastic Kubernetes (EKS) cluster and associated worker instances on AWS 🇺🇦',\n",
       " 'A list of FREE resources to make Web3 accessible to everyone.',\n",
       " 'KrbRelayUp - a universal no-fix local privilege escalation in windows domain environments where LDAP signing is not enforced (the default settings).']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping Repository description\n",
    "RepDisc = driver.find_elements_by_xpath('/html/body/div[4]/main/div[3]/div/div[2]/article/p')\n",
    "len(RepDisc)\n",
    "\n",
    "RDisc=[]\n",
    "for i in RepDisc:\n",
    "    RDisc.append(i.text)\n",
    "        \n",
    "RDisc[0:24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18180b76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['170',\n",
       " '48',\n",
       " '30',\n",
       " '2,394',\n",
       " '5,493',\n",
       " '50',\n",
       " '1,293',\n",
       " '135',\n",
       " '3,766',\n",
       " '108',\n",
       " '50',\n",
       " '4,694',\n",
       " '16',\n",
       " '84',\n",
       " '330',\n",
       " '380',\n",
       " '191',\n",
       " '434',\n",
       " '758',\n",
       " '7,816',\n",
       " '10,654',\n",
       " '208',\n",
       " '541',\n",
       " '271']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping Repository Contributor Count\n",
    "RepCCount = driver.find_elements_by_xpath('/html/body/div[4]/main/div[3]/div/div[2]/article/div[2]/a[2]')\n",
    "len(RepCCount)\n",
    "\n",
    "RepC=[]\n",
    "for i in RepCCount:\n",
    "    RepC.append(i.text)\n",
    "        \n",
    "RepC[0:24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9baca40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Python',\n",
       " 'TypeScript',\n",
       " 'C',\n",
       " 'C#',\n",
       " 'C#',\n",
       " 'Python',\n",
       " 'Python',\n",
       " 'TypeScript',\n",
       " 'Go',\n",
       " 'Rust',\n",
       " 'TypeScript',\n",
       " 'Shell',\n",
       " 'TypeScript',\n",
       " 'Rust',\n",
       " 'Go',\n",
       " 'Scala',\n",
       " 'C#',\n",
       " 'Built by',\n",
       " 'C++',\n",
       " 'Python',\n",
       " 'Java',\n",
       " 'Go',\n",
       " 'Go',\n",
       " 'Python']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping Repository Language\n",
    "RepLanguage = driver.find_elements_by_xpath('/html/body/div[4]/main/div[3]/div/div[2]/article/div[2]/span[1]')\n",
    "len(RepLanguage)\n",
    "\n",
    "RepL=[]\n",
    "for i in RepLanguage:\n",
    "    RepL.append(i.text)\n",
    "        \n",
    "RepL[0:24]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "abe6eead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository Name</th>\n",
       "      <th>Repository Discription</th>\n",
       "      <th>Repository Counter Count</th>\n",
       "      <th>Repository Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BandaiNamcoResearchInc / Bandai-Namco-Research...</td>\n",
       "      <td>This repository provides motion datasets colle...</td>\n",
       "      <td>170</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tencent / tmagic-editor</td>\n",
       "      <td>The core software distribution for the Inform ...</td>\n",
       "      <td>48</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ganelson / inform</td>\n",
       "      <td>Open Source real-time strategy game engine for...</td>\n",
       "      <td>30</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OpenRA / OpenRA</td>\n",
       "      <td>PowerShell for every system!</td>\n",
       "      <td>2,394</td>\n",
       "      <td>C#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PowerShell / PowerShell</td>\n",
       "      <td>模拟手写效果，节约时间。</td>\n",
       "      <td>5,493</td>\n",
       "      <td>C#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>why20021008 / hand-write</td>\n",
       "      <td>🏆 A ranked list of awesome machine learning Py...</td>\n",
       "      <td>50</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ml-tooling / best-of-ml-python</td>\n",
       "      <td>Spacedrive is an open source cross-platform fi...</td>\n",
       "      <td>1,293</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>spacedriveapp / spacedrive</td>\n",
       "      <td>A rule-based tunnel in Go.</td>\n",
       "      <td>135</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Dreamacro / clash</td>\n",
       "      <td>RisingWave: the next-generation streaming data...</td>\n",
       "      <td>3,766</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>singularity-data / risingwave</td>\n",
       "      <td>JSON Hero is an open-source, beautiful JSON ex...</td>\n",
       "      <td>108</td>\n",
       "      <td>Rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>jsonhero-io / jsonhero-web</td>\n",
       "      <td>Papers from the computer science community to ...</td>\n",
       "      <td>50</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>papers-we-love / papers-we-love</td>\n",
       "      <td>Translate your TypeScript errors into plain En...</td>\n",
       "      <td>4,694</td>\n",
       "      <td>Shell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>mattpocock / ts-error-translator</td>\n",
       "      <td>🐢 Magical shell history</td>\n",
       "      <td>16</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ellie / atuin</td>\n",
       "      <td>The Optimism monorepo</td>\n",
       "      <td>84</td>\n",
       "      <td>Rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ethereum-optimism / optimism</td>\n",
       "      <td>Make stream processing easier! Flink &amp; Spark d...</td>\n",
       "      <td>330</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>streamxhub / streamx</td>\n",
       "      <td>Main repository for the Core WCF project</td>\n",
       "      <td>380</td>\n",
       "      <td>Scala</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CoreWCF / CoreWCF</td>\n",
       "      <td>收集整理 GitHub 上高质量、有趣的开源项目。</td>\n",
       "      <td>191</td>\n",
       "      <td>C#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Wechat-ggGitHub / Awesome-GitHub-Repo</td>\n",
       "      <td>Pilot – mini game engine for games104</td>\n",
       "      <td>434</td>\n",
       "      <td>Built by</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>BoomingTech / Pilot</td>\n",
       "      <td>分享 GitHub 上有趣、入门级的开源项目。Share interesting, entr...</td>\n",
       "      <td>758</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>521xueweihan / HelloGitHub</td>\n",
       "      <td>Apache Flink</td>\n",
       "      <td>7,816</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>apache / flink</td>\n",
       "      <td>Optimized Go Compression Packages</td>\n",
       "      <td>10,654</td>\n",
       "      <td>Java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>klauspost / compress</td>\n",
       "      <td>KEDA is a Kubernetes-based Event Driven Autosc...</td>\n",
       "      <td>208</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>kedacore / keda</td>\n",
       "      <td>Top2Vec learns jointly embedded topic, documen...</td>\n",
       "      <td>541</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ddangelov / Top2Vec</td>\n",
       "      <td>Wireit upgrades your npm scripts to make them ...</td>\n",
       "      <td>271</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Repository Name  \\\n",
       "0   BandaiNamcoResearchInc / Bandai-Namco-Research...   \n",
       "1                             Tencent / tmagic-editor   \n",
       "2                                   ganelson / inform   \n",
       "3                                     OpenRA / OpenRA   \n",
       "4                             PowerShell / PowerShell   \n",
       "5                            why20021008 / hand-write   \n",
       "6                      ml-tooling / best-of-ml-python   \n",
       "7                          spacedriveapp / spacedrive   \n",
       "8                                   Dreamacro / clash   \n",
       "9                       singularity-data / risingwave   \n",
       "10                         jsonhero-io / jsonhero-web   \n",
       "11                    papers-we-love / papers-we-love   \n",
       "12                   mattpocock / ts-error-translator   \n",
       "13                                      ellie / atuin   \n",
       "14                       ethereum-optimism / optimism   \n",
       "15                               streamxhub / streamx   \n",
       "16                                  CoreWCF / CoreWCF   \n",
       "17              Wechat-ggGitHub / Awesome-GitHub-Repo   \n",
       "18                                BoomingTech / Pilot   \n",
       "19                         521xueweihan / HelloGitHub   \n",
       "20                                     apache / flink   \n",
       "21                               klauspost / compress   \n",
       "22                                    kedacore / keda   \n",
       "23                                ddangelov / Top2Vec   \n",
       "\n",
       "                               Repository Discription  \\\n",
       "0   This repository provides motion datasets colle...   \n",
       "1   The core software distribution for the Inform ...   \n",
       "2   Open Source real-time strategy game engine for...   \n",
       "3                        PowerShell for every system!   \n",
       "4                                        模拟手写效果，节约时间。   \n",
       "5   🏆 A ranked list of awesome machine learning Py...   \n",
       "6   Spacedrive is an open source cross-platform fi...   \n",
       "7                          A rule-based tunnel in Go.   \n",
       "8   RisingWave: the next-generation streaming data...   \n",
       "9   JSON Hero is an open-source, beautiful JSON ex...   \n",
       "10  Papers from the computer science community to ...   \n",
       "11  Translate your TypeScript errors into plain En...   \n",
       "12                            🐢 Magical shell history   \n",
       "13                              The Optimism monorepo   \n",
       "14  Make stream processing easier! Flink & Spark d...   \n",
       "15           Main repository for the Core WCF project   \n",
       "16                          收集整理 GitHub 上高质量、有趣的开源项目。   \n",
       "17              Pilot – mini game engine for games104   \n",
       "18  分享 GitHub 上有趣、入门级的开源项目。Share interesting, entr...   \n",
       "19                                       Apache Flink   \n",
       "20                  Optimized Go Compression Packages   \n",
       "21  KEDA is a Kubernetes-based Event Driven Autosc...   \n",
       "22  Top2Vec learns jointly embedded topic, documen...   \n",
       "23  Wireit upgrades your npm scripts to make them ...   \n",
       "\n",
       "   Repository Counter Count Repository Language  \n",
       "0                       170              Python  \n",
       "1                        48          TypeScript  \n",
       "2                        30                   C  \n",
       "3                     2,394                  C#  \n",
       "4                     5,493                  C#  \n",
       "5                        50              Python  \n",
       "6                     1,293              Python  \n",
       "7                       135          TypeScript  \n",
       "8                     3,766                  Go  \n",
       "9                       108                Rust  \n",
       "10                       50          TypeScript  \n",
       "11                    4,694               Shell  \n",
       "12                       16          TypeScript  \n",
       "13                       84                Rust  \n",
       "14                      330                  Go  \n",
       "15                      380               Scala  \n",
       "16                      191                  C#  \n",
       "17                      434            Built by  \n",
       "18                      758                 C++  \n",
       "19                    7,816              Python  \n",
       "20                   10,654                Java  \n",
       "21                      208                  Go  \n",
       "22                      541                  Go  \n",
       "23                      271              Python  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.DataFrame({})\n",
    "df[\"Repository Name\"] = RName[0:24]\n",
    "df[\"Repository Discription\"] = RDisc[0:24]\n",
    "df[\"Repository Counter Count\"] = RepC[0:24]\n",
    "df[\"Repository Language\"] = RepL[0:24]\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1b28d6",
   "metadata": {},
   "source": [
    "6. Scrape the details of top 100 songs on billiboard.com.\n",
    "Url = https:/www.billboard.com/\n",
    "You have to find the following details:\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "823879e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activating the chrome browser\n",
    "\n",
    "PATH = 'E:\\DataTrained\\chromedriver.exe' #extracting path of the webdriver\n",
    "driver = webdriver.Chrome(PATH)\n",
    "try:\n",
    "    url = \"https:/www.billboard.com/\"\n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "    \n",
    "except NoSuchElementException :\n",
    "    print(\"No Login page\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9702a095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['As It Was',\n",
       " 'First Class',\n",
       " 'Heat Waves',\n",
       " 'Big Energy',\n",
       " 'Enemy',\n",
       " 'Stay',\n",
       " \"Don't Think Jesus\",\n",
       " 'Woman',\n",
       " 'Super Gremlin',\n",
       " 'Ghost',\n",
       " 'Thats What I Want',\n",
       " 'Bad Habits',\n",
       " 'abcdefu',\n",
       " 'Shivers',\n",
       " 'Cold Heart (PNAU Remix)',\n",
       " 'Easy On Me',\n",
       " 'Need To Know',\n",
       " 'Save Your Tears',\n",
       " 'One Right Now',\n",
       " 'In A Minute',\n",
       " 'Levitating',\n",
       " \"'Til You Can't\",\n",
       " 'Industry Baby',\n",
       " 'MAMIII',\n",
       " 'Bam Bam',\n",
       " 'Hrs And Hrs',\n",
       " \"We Don't Talk About Bruno\",\n",
       " 'Right On',\n",
       " 'Never Say Never',\n",
       " \"Doin' This\",\n",
       " 'Wasted On You',\n",
       " 'AA',\n",
       " 'Good 4 U',\n",
       " 'Sweetest Pie',\n",
       " 'Fingers Crossed',\n",
       " 'I Hate U',\n",
       " 'Boyfriend',\n",
       " 'To The Moon!',\n",
       " 'You Right',\n",
       " 'Numb Little Bug',\n",
       " 'Fancy Like',\n",
       " 'Sand In My Boots',\n",
       " 'What Happened To Virgil',\n",
       " 'Pushin P',\n",
       " 'Beers On Me',\n",
       " 'The Motto',\n",
       " \"She's All I Wanna Be\",\n",
       " \"When You're Gone\",\n",
       " 'Buy Dirt',\n",
       " 'About Damn Time',\n",
       " 'Shake It',\n",
       " 'Light Switch',\n",
       " 'If I Was A Cowboy',\n",
       " 'Peru',\n",
       " 'Flowers',\n",
       " 'Nail Tech',\n",
       " 'Freaky Deaky',\n",
       " '23',\n",
       " 'Trouble With A Heartbreak',\n",
       " 'Broadway Girls',\n",
       " 'Heart On Fire',\n",
       " 'No Love',\n",
       " 'Surface Pressure',\n",
       " 'Slow Down Summer',\n",
       " 'Flower Shops',\n",
       " 'Never Wanted To Be That Girl',\n",
       " 'Me Or Sum',\n",
       " 'Ahhh Ha',\n",
       " 'Give Heaven Some Hell',\n",
       " 'Handsomer',\n",
       " 'Envolver',\n",
       " 'Do We Have A Problem?',\n",
       " 'Get Into It (Yuh)',\n",
       " 'Rumors',\n",
       " 'Take My Name',\n",
       " 'Damn Strait',\n",
       " 'Circles Around This Town',\n",
       " 'In My Head',\n",
       " 'Nobody Like U',\n",
       " 'Soy El Unico',\n",
       " 'I Love You So',\n",
       " 'Come Back As A Country Boy',\n",
       " 'GINE',\n",
       " 'City Of Gods',\n",
       " 'Complete Mess',\n",
       " 'Leave You Alone',\n",
       " 'Bones',\n",
       " 'Banking On Me',\n",
       " 'She Likes It',\n",
       " 'Pressure',\n",
       " 'Desesperados',\n",
       " 'Over',\n",
       " 'The Family Madrigal',\n",
       " 'Hate Our Love',\n",
       " 'Dos Oruguitas',\n",
       " 'P Power',\n",
       " 'Money So Big',\n",
       " 'Blick Blick!',\n",
       " 'Fall In Love']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping Song Name\n",
    "SongName = driver.find_elements_by_xpath('/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div/ul/li/ul/li/h3')\n",
    "len(SongName)\n",
    "\n",
    "SongN=[]\n",
    "for i in SongName:\n",
    "    SongN.append(i.text)\n",
    "        \n",
    "SongN[0:99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "98782985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Harry Styles',\n",
       " 'Jack Harlow',\n",
       " 'Glass Animals',\n",
       " 'Latto',\n",
       " 'Imagine Dragons X JID',\n",
       " 'The Kid LAROI & Justin Bieber',\n",
       " 'Morgan Wallen',\n",
       " 'Doja Cat',\n",
       " 'Kodak Black',\n",
       " 'Justin Bieber',\n",
       " 'Lil Nas X',\n",
       " 'Ed Sheeran',\n",
       " 'GAYLE',\n",
       " 'Ed Sheeran',\n",
       " 'Elton John & Dua Lipa',\n",
       " 'Adele',\n",
       " 'Doja Cat',\n",
       " 'The Weeknd & Ariana Grande',\n",
       " 'Post Malone & The Weeknd',\n",
       " 'Lil Baby',\n",
       " 'Dua Lipa',\n",
       " 'Cody Johnson',\n",
       " 'Lil Nas X & Jack Harlow',\n",
       " 'Becky G X Karol G',\n",
       " 'Camila Cabello Featuring Ed Sheeran',\n",
       " 'Muni Long',\n",
       " 'Carolina Gaitan, Mauro Castillo, Adassa, Rhenzy Feliz, Diane Guerrero, Stephanie Beatriz & Encanto Cast',\n",
       " 'Lil Baby',\n",
       " 'Cole Swindell / Lainey Wilson',\n",
       " 'Luke Combs',\n",
       " 'Morgan Wallen',\n",
       " 'Walker Hayes',\n",
       " 'Olivia Rodrigo',\n",
       " 'Megan Thee Stallion & Dua Lipa',\n",
       " 'Lauren Spencer-Smith',\n",
       " 'SZA',\n",
       " 'Dove Cameron',\n",
       " 'JNR CHOI & Sam Tompkins',\n",
       " 'Doja Cat & The Weeknd',\n",
       " 'Em Beihold',\n",
       " 'Walker Hayes',\n",
       " 'Morgan Wallen',\n",
       " 'Lil Durk Featuring Gunna',\n",
       " 'Gunna & Future Featuring Young Thug',\n",
       " 'Dierks Bentley, BRELAND & HARDY',\n",
       " 'Tiesto & Ava Max',\n",
       " 'Tate McRae',\n",
       " 'Shawn Mendes',\n",
       " 'Jordan Davis Featuring Luke Bryan',\n",
       " 'Lizzo',\n",
       " 'Kay Flock, Cardi B, Dougie B & Bory300',\n",
       " 'Charlie Puth',\n",
       " 'Miranda Lambert',\n",
       " 'Fireboy DML & Ed Sheeran',\n",
       " 'Lauren Spencer-Smith',\n",
       " 'Jack Harlow',\n",
       " 'Tyga X Doja Cat',\n",
       " 'Sam Hunt',\n",
       " 'Jason Aldean',\n",
       " 'Lil Durk Featuring Morgan Wallen',\n",
       " 'Eric Church',\n",
       " 'Summer Walker & SZA',\n",
       " 'Jessica Darrow',\n",
       " 'Thomas Rhett',\n",
       " 'ERNEST Featuring Morgan Wallen',\n",
       " 'Carly Pearce & Ashley McBryde',\n",
       " 'Nardo Wick, Lil Baby & Future',\n",
       " 'Lil Durk',\n",
       " 'HARDY',\n",
       " 'Russ Featuring Ktlyn',\n",
       " 'Anitta',\n",
       " 'Nicki Minaj X Lil Baby',\n",
       " 'Doja Cat',\n",
       " 'Gucci Mane Featuring Lil Durk',\n",
       " 'Parmalee',\n",
       " 'Scotty McCreery',\n",
       " 'Maren Morris',\n",
       " 'Lil Tjay',\n",
       " \"4*TOWN (From Disney And Pixar's Turning Red)\",\n",
       " 'Yahritza y Su Esencia',\n",
       " 'The Walters',\n",
       " 'Blake Shelton',\n",
       " '6ix9ine',\n",
       " 'Fivio Foreign, Kanye West & Alicia Keys',\n",
       " '5 Seconds Of Summer',\n",
       " 'Kane Brown',\n",
       " 'Imagine Dragons',\n",
       " 'Gunna',\n",
       " 'Russell Dickerson & Jake Scott',\n",
       " 'Ari Lennox',\n",
       " 'Rauw Alejandro & Chencho Corleone',\n",
       " 'Lucky Daye',\n",
       " 'Stephanie Beatriz, Olga Merediz & Encanto Cast',\n",
       " 'Queen Naija & Big Sean',\n",
       " 'Sebastian Yatra',\n",
       " 'Gunna Featuring Drake',\n",
       " 'Yeat',\n",
       " 'Coi Leray & Nicki Minaj',\n",
       " 'Bailey Zimmerman']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping Artist Name\n",
    "ArtistName = driver.find_elements_by_xpath('/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div/ul/li[4]/ul/li[1]/span')\n",
    "len(ArtistName)\n",
    "\n",
    "ArtistN=[]\n",
    "for i in ArtistName:\n",
    "    ArtistN.append(i.text)\n",
    "        \n",
    "ArtistN[0:99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d240de45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2',\n",
       " '1',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '-',\n",
       " '8',\n",
       " '7',\n",
       " '9',\n",
       " '10',\n",
       " '12',\n",
       " '11',\n",
       " '15',\n",
       " '16',\n",
       " '17',\n",
       " '20',\n",
       " '23',\n",
       " '24',\n",
       " '14',\n",
       " '21',\n",
       " '22',\n",
       " '19',\n",
       " '30',\n",
       " '25',\n",
       " '26',\n",
       " '18',\n",
       " '13',\n",
       " '27',\n",
       " '31',\n",
       " '36',\n",
       " '32',\n",
       " '28',\n",
       " '33',\n",
       " '34',\n",
       " '29',\n",
       " '44',\n",
       " '42',\n",
       " '37',\n",
       " '45',\n",
       " '38',\n",
       " '48',\n",
       " '39',\n",
       " '35',\n",
       " '41',\n",
       " '49',\n",
       " '50',\n",
       " '52',\n",
       " '47',\n",
       " '-',\n",
       " '-',\n",
       " '43',\n",
       " '68',\n",
       " '53',\n",
       " '-',\n",
       " '40',\n",
       " '60',\n",
       " '55',\n",
       " '73',\n",
       " '58',\n",
       " '63',\n",
       " '59',\n",
       " '56',\n",
       " '51',\n",
       " '67',\n",
       " '65',\n",
       " '66',\n",
       " '61',\n",
       " '76',\n",
       " '54',\n",
       " '74',\n",
       " '70',\n",
       " '82',\n",
       " '77',\n",
       " '80',\n",
       " '89',\n",
       " '57',\n",
       " '64',\n",
       " '72',\n",
       " '69',\n",
       " '86',\n",
       " '84',\n",
       " '-',\n",
       " '71',\n",
       " '85',\n",
       " '-',\n",
       " '94',\n",
       " '87',\n",
       " '90',\n",
       " '92',\n",
       " '98',\n",
       " '96',\n",
       " '78',\n",
       " '-',\n",
       " '93',\n",
       " '91',\n",
       " '-',\n",
       " '95',\n",
       " '-']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping Last week rank\n",
    "LastRank = driver.find_elements_by_xpath('/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div/ul/li[4]/ul/li[4]/span')\n",
    "len(LastRank)\n",
    "\n",
    "LastR=[]\n",
    "for i in LastRank:\n",
    "    LastR.append(i.text)\n",
    "        \n",
    "LastR[0:99]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5555264d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3',\n",
       " '2',\n",
       " '66',\n",
       " '26',\n",
       " '22',\n",
       " '41',\n",
       " '1',\n",
       " '38',\n",
       " '24',\n",
       " '30',\n",
       " '31',\n",
       " '43',\n",
       " '22',\n",
       " '32',\n",
       " '33',\n",
       " '28',\n",
       " '45',\n",
       " '68',\n",
       " '24',\n",
       " '2',\n",
       " '76',\n",
       " '28',\n",
       " '39',\n",
       " '10',\n",
       " '7',\n",
       " '17',\n",
       " '17',\n",
       " '2',\n",
       " '14',\n",
       " '19',\n",
       " '23',\n",
       " '15',\n",
       " '49',\n",
       " '6',\n",
       " '16',\n",
       " '20',\n",
       " '10',\n",
       " '8',\n",
       " '42',\n",
       " '12',\n",
       " '44',\n",
       " '40',\n",
       " '6',\n",
       " '15',\n",
       " '17',\n",
       " '12',\n",
       " '11',\n",
       " '3',\n",
       " '37',\n",
       " '1',\n",
       " '1',\n",
       " '13',\n",
       " '12',\n",
       " '12',\n",
       " '1',\n",
       " '9',\n",
       " '8',\n",
       " '17',\n",
       " '5',\n",
       " '18',\n",
       " '22',\n",
       " '16',\n",
       " '17',\n",
       " '9',\n",
       " '13',\n",
       " '15',\n",
       " '15',\n",
       " '9',\n",
       " '8',\n",
       " '7',\n",
       " '4',\n",
       " '11',\n",
       " '20',\n",
       " '12',\n",
       " '3',\n",
       " '3',\n",
       " '15',\n",
       " '3',\n",
       " '5',\n",
       " '4',\n",
       " '14',\n",
       " '12',\n",
       " '1',\n",
       " '9',\n",
       " '3',\n",
       " '1',\n",
       " '6',\n",
       " '9',\n",
       " '5',\n",
       " '17',\n",
       " '3',\n",
       " '5',\n",
       " '16',\n",
       " '2',\n",
       " '16',\n",
       " '14',\n",
       " '4',\n",
       " '4',\n",
       " '1']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping Last week rank\n",
    "PeakRank= driver.find_elements_by_xpath('/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div/ul/li[4]/ul/li[5]/span')\n",
    "len(PeakRank)\n",
    "\n",
    "PRank=[]\n",
    "for i in PeakRank:\n",
    "    PRank.append(i.text)\n",
    "        \n",
    "PRank[0:99]\n",
    "\n",
    "# Scraping Last weeks on chart\n",
    "WeeksChart= driver.find_elements_by_xpath('/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div/ul/li[4]/ul/li[6]/span')\n",
    "len(WeeksChart)\n",
    "\n",
    "WChart=[]\n",
    "for i in WeeksChart:\n",
    "    WChart.append(i.text)\n",
    "        \n",
    "WChart[0:99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4d189051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song Name</th>\n",
       "      <th>Artist Name</th>\n",
       "      <th>Last week rank</th>\n",
       "      <th>Peak rank</th>\n",
       "      <th>Weeks on board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As It Was</td>\n",
       "      <td>Harry Styles</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>First Class</td>\n",
       "      <td>Jack Harlow</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Heat Waves</td>\n",
       "      <td>Glass Animals</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Big Energy</td>\n",
       "      <td>Latto</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Enemy</td>\n",
       "      <td>Imagine Dragons X JID</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>P Power</td>\n",
       "      <td>Gunna Featuring Drake</td>\n",
       "      <td>91</td>\n",
       "      <td>24</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Money So Big</td>\n",
       "      <td>Yeat</td>\n",
       "      <td>-</td>\n",
       "      <td>95</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Blick Blick!</td>\n",
       "      <td>Coi Leray &amp; Nicki Minaj</td>\n",
       "      <td>95</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Fall In Love</td>\n",
       "      <td>Bailey Zimmerman</td>\n",
       "      <td>-</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>X Ultima Vez</td>\n",
       "      <td>Daddy Yankee &amp; Bad Bunny</td>\n",
       "      <td>99</td>\n",
       "      <td>73</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Song Name               Artist Name Last week rank Peak rank  \\\n",
       "0      As It Was              Harry Styles              2         1   \n",
       "1    First Class               Jack Harlow              1         1   \n",
       "2     Heat Waves             Glass Animals              3         1   \n",
       "3     Big Energy                     Latto              4         3   \n",
       "4          Enemy     Imagine Dragons X JID              5         5   \n",
       "..           ...                       ...            ...       ...   \n",
       "95       P Power     Gunna Featuring Drake             91        24   \n",
       "96  Money So Big                      Yeat              -        95   \n",
       "97  Blick Blick!   Coi Leray & Nicki Minaj             95        37   \n",
       "98  Fall In Love          Bailey Zimmerman              -        99   \n",
       "99  X Ultima Vez  Daddy Yankee & Bad Bunny             99        73   \n",
       "\n",
       "   Weeks on board  \n",
       "0               3  \n",
       "1               2  \n",
       "2              66  \n",
       "3              26  \n",
       "4              22  \n",
       "..            ...  \n",
       "95             14  \n",
       "96              4  \n",
       "97              4  \n",
       "98              1  \n",
       "99              3  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making a Data Frame\n",
    "df=pd.DataFrame ({})\n",
    "df[\"Song Name\"] = SongN\n",
    "df[\"Artist Name\"] = ArtistN\n",
    "df[\"Last week rank\"] = LastR\n",
    "df[\"Peak rank\"] = PRank\n",
    "df[\"Weeks on board\"] = WChart\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e022aeb",
   "metadata": {},
   "source": [
    "7. Scrape the details of Data science recruiters from naukri.com.\n",
    "Url = https://www.naukri.com/\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Designation\n",
    "C) Company\n",
    "D) Skills they hire for\n",
    "E) Location\n",
    "Note: - From naukri.com homepage click on the recruiters option and the on the search pane type Data science and\n",
    "click on search. All this should be done through cod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2979c784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activating the chrome browser\n",
    "\n",
    "PATH = 'E:\\DataTrained\\chromedriver.exe' #extracting path of the webdriver\n",
    "driver = webdriver.Chrome(PATH)\n",
    "try:\n",
    "    url = \"https://www.naukri.com/data-science-jobs?k=data%20science\"\n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "    \n",
    "except NoSuchElementException :\n",
    "    print(\"No Login page\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "25b77854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bangalore/Bengaluru',\n",
       " 'Pune',\n",
       " 'Chennai, Bangalore/Bengaluru, Delhi / NCR',\n",
       " 'Chennai',\n",
       " 'Chennai',\n",
       " '(WFH during Covid)',\n",
       " 'Bhubaneswar, Hyderabad/Secunderabad',\n",
       " 'Pune',\n",
       " 'Pune',\n",
       " 'Gurgaon/Gurugram',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Kolkata, Mumbai, Visakhapatnam, Hyderabad/Secunderabad, Pune, Chennai, Ahmedabad, Bangalore/Bengaluru, Delhi / NCR',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Gurgaon/Gurugram',\n",
       " 'Gurgaon/Gurugram',\n",
       " 'Mumbai',\n",
       " 'Noida, Bangalore/Bengaluru',\n",
       " 'Pune, Bangalore/Bengaluru',\n",
       " 'Gurgaon/Gurugram',\n",
       " 'Bangalore/Bengaluru']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping Commapany Name\n",
    "Commapany_Name= driver.find_elements_by_xpath('/html/body/div[1]/div[3]/div[2]/section[2]/div[2]/article/div[1]/div/div/a[1]')\n",
    "len(Commapany_Name)\n",
    "\n",
    "CName=[]\n",
    "for i in Commapany_Name:\n",
    "    CName.append(i.text)\n",
    "        \n",
    "CName\n",
    "\n",
    "# Scraping Designation Name\n",
    "Designation_Name= driver.find_elements_by_xpath('/html/body/div[1]/div[3]/div[2]/section[2]/div[2]/article/div/div/a')\n",
    "len(Designation_Name)\n",
    "\n",
    "DName=[]\n",
    "for i in Designation_Name:\n",
    "    DName.append(i.text)\n",
    "        \n",
    "DName\n",
    "\n",
    "# Scraping Skills they hire\n",
    "Skills_Name= driver.find_elements_by_xpath('/html/body/div[1]/div[3]/div[2]/section[2]/div[2]/article/ul')\n",
    "len(Skills_Name)\n",
    "\n",
    "SName=[]\n",
    "for i in Skills_Name:\n",
    "    SName.append(i.text)\n",
    "        \n",
    "\n",
    "SName\n",
    "\n",
    "# Scraping Location they hire\n",
    "Location_Name= driver.find_elements_by_xpath('/html/body/div[1]/div[3]/div[2]/section[2]/div[2]/article/div[1]/div/ul/li[3]/span')\n",
    "len(Location_Name)\n",
    "\n",
    "LName=[]\n",
    "for i in Location_Name:\n",
    "    LName.append(i.text)\n",
    "        \n",
    "\n",
    "LName\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5600dc6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Designation</th>\n",
       "      <th>Location</th>\n",
       "      <th>Skills Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Epsilon</td>\n",
       "      <td>Data Science Analyst 2</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Data analysis,Factor analysis,data science,SAS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MSD Pharmaceuticals</td>\n",
       "      <td>Opening For Manager / Sr. Manager Data Science</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Data Science,python,Django,MySQL,Data Analytic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HCL Technologies</td>\n",
       "      <td>HCL || Data Science</td>\n",
       "      <td>Chennai, Bangalore/Bengaluru, Delhi / NCR</td>\n",
       "      <td>Azure Functions,ETL,analytical,Azure,Tableau,c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TIGER ANALYTICS INDIA CONSULTING PRIVATE LIMITED</td>\n",
       "      <td>Analyst: Data Science Insights</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>PowerBI,Tableau,python,Data Analysis,R,Pandas,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tiger Analytics India LLP</td>\n",
       "      <td>Senior Analyst - Data Science</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Python,R,verbal communication,written,IT Skill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HighRadius</td>\n",
       "      <td>Data Science/Data scientist| Product Company|5...</td>\n",
       "      <td>(WFH during Covid)</td>\n",
       "      <td>Machine Learning,IT Skills,Python,Data Science...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Xoriant</td>\n",
       "      <td>Data Science Engineer</td>\n",
       "      <td>Bhubaneswar, Hyderabad/Secunderabad</td>\n",
       "      <td>Data Science,S3,Spark,Analytics,AWS SageMaker,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>INFOWEB</td>\n",
       "      <td>Data Analyst / Data Science</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Data Science,Data Quality,Predictive Analytics...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>ACN - Applied Intelligence - CC - Data Science...</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Data Science,Applied intelligence,development,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Optum</td>\n",
       "      <td>Director - Data Engineering - Data Science Pyt...</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Python,Data Science,NoSQL,EDA,Big Data,Kafka,J...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Catalyst</td>\n",
       "      <td>Data Science/Analysis Expert - Machine Learning</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>IT Skills,Python,Data Science,Machine Learning...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MarketScope</td>\n",
       "      <td>Mentor - Data Analyst/Data Science</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>IT Skills,Python,Big Data,Tableau,Julia,Data S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Google</td>\n",
       "      <td>Product Analyst, Google Assistant Data Science</td>\n",
       "      <td>Kolkata, Mumbai, Visakhapatnam, Hyderabad/Secu...</td>\n",
       "      <td>IT Skills,Python,Computer science,Data analysi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Huquo Consulting Pvt. Ltd</td>\n",
       "      <td>Senior Analyst - Data Science - IIT/NIT/IIM/XL...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Data Science,R,Python,Tableau,verbal communica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Huquo Consulting Pvt. Ltd</td>\n",
       "      <td>Senior Analyst - Data Science - IIT/NIT/IIM/XL...</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Python,Tableau,verbal communications,SAS,data ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>TATA CAPITAL LTD</td>\n",
       "      <td>Associate - Data Science - Analytics</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Customer acquisition,Logistic regression,Bfsi,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>FLIP ROBO TECHNOLOGIES PRIVATE LIMITED</td>\n",
       "      <td>Hiring For Data Science Intern</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Data Science,Natural Language Processing,Machi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TM Inputs &amp; Services Pvt. Ltd.</td>\n",
       "      <td>Analyst/Sr Analyst - Data Science</td>\n",
       "      <td>Noida, Bangalore/Bengaluru</td>\n",
       "      <td>data science,machine learning models</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>ACN - Applied Intelligence - CC - Data Science...</td>\n",
       "      <td>Pune, Bangalore/Bengaluru</td>\n",
       "      <td>Machine Learning,Data Science,Applied intellig...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Name  \\\n",
       "0                                            Epsilon   \n",
       "1                                MSD Pharmaceuticals   \n",
       "2                                   HCL Technologies   \n",
       "3   TIGER ANALYTICS INDIA CONSULTING PRIVATE LIMITED   \n",
       "4                          Tiger Analytics India LLP   \n",
       "5                                         HighRadius   \n",
       "6                                            Xoriant   \n",
       "7                                            INFOWEB   \n",
       "8                                          Accenture   \n",
       "9                                              Optum   \n",
       "10                                          Catalyst   \n",
       "11                                       MarketScope   \n",
       "12                                            Google   \n",
       "13                         Huquo Consulting Pvt. Ltd   \n",
       "14                         Huquo Consulting Pvt. Ltd   \n",
       "15                                  TATA CAPITAL LTD   \n",
       "16            FLIP ROBO TECHNOLOGIES PRIVATE LIMITED   \n",
       "17                    TM Inputs & Services Pvt. Ltd.   \n",
       "18                                         Accenture   \n",
       "\n",
       "                                          Designation  \\\n",
       "0                              Data Science Analyst 2   \n",
       "1      Opening For Manager / Sr. Manager Data Science   \n",
       "2                                 HCL || Data Science   \n",
       "3                      Analyst: Data Science Insights   \n",
       "4                       Senior Analyst - Data Science   \n",
       "5   Data Science/Data scientist| Product Company|5...   \n",
       "6                               Data Science Engineer   \n",
       "7                         Data Analyst / Data Science   \n",
       "8   ACN - Applied Intelligence - CC - Data Science...   \n",
       "9   Director - Data Engineering - Data Science Pyt...   \n",
       "10    Data Science/Analysis Expert - Machine Learning   \n",
       "11                 Mentor - Data Analyst/Data Science   \n",
       "12     Product Analyst, Google Assistant Data Science   \n",
       "13  Senior Analyst - Data Science - IIT/NIT/IIM/XL...   \n",
       "14  Senior Analyst - Data Science - IIT/NIT/IIM/XL...   \n",
       "15               Associate - Data Science - Analytics   \n",
       "16                     Hiring For Data Science Intern   \n",
       "17                  Analyst/Sr Analyst - Data Science   \n",
       "18  ACN - Applied Intelligence - CC - Data Science...   \n",
       "\n",
       "                                             Location  \\\n",
       "0                                 Bangalore/Bengaluru   \n",
       "1                                                Pune   \n",
       "2           Chennai, Bangalore/Bengaluru, Delhi / NCR   \n",
       "3                                             Chennai   \n",
       "4                                             Chennai   \n",
       "5                                  (WFH during Covid)   \n",
       "6                 Bhubaneswar, Hyderabad/Secunderabad   \n",
       "7                                                Pune   \n",
       "8                                                Pune   \n",
       "9                                    Gurgaon/Gurugram   \n",
       "10                                Bangalore/Bengaluru   \n",
       "11                                Bangalore/Bengaluru   \n",
       "12  Kolkata, Mumbai, Visakhapatnam, Hyderabad/Secu...   \n",
       "13                                Bangalore/Bengaluru   \n",
       "14                                   Gurgaon/Gurugram   \n",
       "15                                   Gurgaon/Gurugram   \n",
       "16                                             Mumbai   \n",
       "17                         Noida, Bangalore/Bengaluru   \n",
       "18                          Pune, Bangalore/Bengaluru   \n",
       "\n",
       "                                      Skills Required  \n",
       "0   Data analysis,Factor analysis,data science,SAS...  \n",
       "1   Data Science,python,Django,MySQL,Data Analytic...  \n",
       "2   Azure Functions,ETL,analytical,Azure,Tableau,c...  \n",
       "3   PowerBI,Tableau,python,Data Analysis,R,Pandas,...  \n",
       "4   Python,R,verbal communication,written,IT Skill...  \n",
       "5   Machine Learning,IT Skills,Python,Data Science...  \n",
       "6   Data Science,S3,Spark,Analytics,AWS SageMaker,...  \n",
       "7   Data Science,Data Quality,Predictive Analytics...  \n",
       "8   Data Science,Applied intelligence,development,...  \n",
       "9   Python,Data Science,NoSQL,EDA,Big Data,Kafka,J...  \n",
       "10  IT Skills,Python,Data Science,Machine Learning...  \n",
       "11  IT Skills,Python,Big Data,Tableau,Julia,Data S...  \n",
       "12  IT Skills,Python,Computer science,Data analysi...  \n",
       "13  Data Science,R,Python,Tableau,verbal communica...  \n",
       "14  Python,Tableau,verbal communications,SAS,data ...  \n",
       "15  Customer acquisition,Logistic regression,Bfsi,...  \n",
       "16  Data Science,Natural Language Processing,Machi...  \n",
       "17               data science,machine learning models  \n",
       "18  Machine Learning,Data Science,Applied intellig...  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making a Data Frame\n",
    "df = pd .DataFrame ({})\n",
    "df[\"Name\"] =CName [0:19]\n",
    "df[\"Designation\"] = DName[0:19]\n",
    "df[\"Location\"] = LName[0:19]\n",
    "df[\"Skills Required\"] = SName[0:19]\n",
    "df['Skills Required'] = df['Skills Required'].str.replace('\\n',',')\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc465a3",
   "metadata": {},
   "source": [
    "8. Scrape the details of Highest selling novels.\n",
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey\u0002compare/\n",
    "You have to find the following details:\n",
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "aea9b982",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH= 'E:\\DataTrained\\chromedriver.exe' #extracting path of the webdriver\n",
    "driver = webdriver.Chrome(PATH)\n",
    "try:\n",
    "    url = \"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/\"\n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "    \n",
    "except NoSuchElementException :\n",
    "    print(\"No Login page\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6b749f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping Data from the Table \n",
    "\n",
    "BookName= driver.find_elements_by_xpath('/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr/td[2]')\n",
    "len(BookName)\n",
    "\n",
    "AuthorName= driver.find_elements_by_xpath('/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr/td[3]')\n",
    "len(AuthorName)\n",
    "\n",
    "VolumesSold= driver.find_elements_by_xpath('/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr/td[4]')\n",
    "len(VolumesSold)\n",
    "\n",
    "Publisher= driver.find_elements_by_xpath('/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr/td[5]')\n",
    "len(Publisher)\n",
    "\n",
    "Genre= driver.find_elements_by_xpath('/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr/td[3]')\n",
    "len(Genre)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "db1000bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Brown, Dan',\n",
       " 'Rowling, J.K.',\n",
       " 'Rowling, J.K.',\n",
       " 'Rowling, J.K.',\n",
       " 'James, E. L.',\n",
       " 'Rowling, J.K.',\n",
       " 'Rowling, J.K.',\n",
       " 'Rowling, J.K.',\n",
       " 'Brown, Dan',\n",
       " 'Rowling, J.K.',\n",
       " 'James, E. L.',\n",
       " 'Meyer, Stephenie',\n",
       " 'Larsson, Stieg',\n",
       " 'James, E. L.',\n",
       " 'Brown, Dan',\n",
       " 'Meyer, Stephenie',\n",
       " 'Brown, Dan',\n",
       " 'Meyer, Stephenie',\n",
       " 'Sebold, Alice',\n",
       " 'Haddon, Mark',\n",
       " 'Brown, Dan',\n",
       " 'Bryson, Bill',\n",
       " 'Larsson, Stieg',\n",
       " 'Meyer, Stephenie',\n",
       " 'Carle, Eric',\n",
       " 'Donaldson, Julia',\n",
       " 'Oliver, Jamie',\n",
       " 'Hosseini, Khaled',\n",
       " 'Nicholls, David',\n",
       " 'Hosseini, Khaled',\n",
       " 'Larsson, Stieg',\n",
       " 'Niffenegger, Audrey',\n",
       " 'McEwan, Ian',\n",
       " 'Fielding, Helen',\n",
       " 'Clarkson, Jeremy',\n",
       " 'Bernieres, Louis de',\n",
       " 'Kay, Peter',\n",
       " 'Martel, Yann',\n",
       " 'Stephenson, Pamela',\n",
       " 'Pelzer, Dave',\n",
       " 'Donaldson, Julia',\n",
       " 'McCourt, Frank',\n",
       " 'Faulks, Sebastian',\n",
       " 'Pullman, Philip',\n",
       " 'Mosse, Kate',\n",
       " 'Rowling, J.K.',\n",
       " 'Stockett, Kathryn',\n",
       " 'Parsons, Tony',\n",
       " 'Golden, Arthur',\n",
       " 'McCall Smith, Alexander',\n",
       " 'Hislop, Victoria',\n",
       " 'Ahern, Cecelia',\n",
       " 'McKeith, Gillian',\n",
       " 'Zafon, Carlos Ruiz',\n",
       " 'Rowling, J.K.',\n",
       " 'Grisham, John',\n",
       " 'Atkins, Robert C.',\n",
       " 'Pullman, Philip',\n",
       " 'Truss, Lynne',\n",
       " 'Smith, Delia',\n",
       " 'Harris, Joanne',\n",
       " 'Boyne, John',\n",
       " 'Picoult, Jodi',\n",
       " 'Pullman, Philip',\n",
       " 'Lee, Harper',\n",
       " 'Gray, John',\n",
       " 'French, Dawn',\n",
       " 'Lewycka, Marina',\n",
       " 'Harris, Thomas',\n",
       " 'Tolkien, J. R. R.',\n",
       " 'Moore, Michael',\n",
       " 'Rubenfeld, Jed',\n",
       " 'Osbourne, Sharon',\n",
       " 'Coelho, Paulo',\n",
       " \"O'Grady, Paul\",\n",
       " 'Bryson, Bill',\n",
       " 'Oliver, Jamie',\n",
       " 'Fielding, Helen',\n",
       " 'Oliver, Jamie',\n",
       " 'McKenna, Paul',\n",
       " 'Bryson, Bill',\n",
       " 'Grisham, John',\n",
       " 'Levy, Andrea',\n",
       " 'Lawson, Nigella',\n",
       " 'Ali, Monica',\n",
       " 'Edwards, Kim',\n",
       " 'Donaldson, Julia',\n",
       " 'Hornby, Nick',\n",
       " 'Brand, Russell',\n",
       " 'Dawkins, Richard',\n",
       " '0',\n",
       " 'Smith, Zadie',\n",
       " 'Morton, Kate',\n",
       " 'Zusak, Markus',\n",
       " 'Binchy, Maeve',\n",
       " 'Harris, Robert',\n",
       " 'Oliver, Jamie',\n",
       " 'Collins, Suzanne',\n",
       " 'Pelzer, Dave',\n",
       " 'Oliver, Jamie']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "BookN=[]\n",
    "for i in BookName:\n",
    "    BookN.append(i.text)\n",
    "        \n",
    "\n",
    "BookN\n",
    "\n",
    "AuthorN=[]\n",
    "for i in AuthorName:\n",
    "    AuthorN.append(i.text)\n",
    "        \n",
    "\n",
    "AuthorN\n",
    "\n",
    "VolumeS=[]\n",
    "for i in VolumesSold:\n",
    "    VolumeS.append(i.text)\n",
    "        \n",
    "\n",
    "VolumeS\n",
    "\n",
    "PublishN=[]\n",
    "for i in Publisher:\n",
    "    PublishN.append(i.text)\n",
    "        \n",
    "\n",
    "PublishN\n",
    "\n",
    "Gen=[]\n",
    "for i in Genre:\n",
    "    Gen.append(i.text)\n",
    "        \n",
    "\n",
    "Gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "348ce517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Volume Sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Brown, Dan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>James, E. L.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Nights of Rain and Stars</td>\n",
       "      <td>Binchy, Maeve</td>\n",
       "      <td>808,900</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Binchy, Maeve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Harris, Robert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book Name       Author Name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "94                           Nights of Rain and Stars     Binchy, Maeve   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "\n",
       "   Volume Sold        Publisher             Genre  \n",
       "0    5,094,805       Transworld        Brown, Dan  \n",
       "1    4,475,152       Bloomsbury     Rowling, J.K.  \n",
       "2    4,200,654       Bloomsbury     Rowling, J.K.  \n",
       "3    4,179,479       Bloomsbury     Rowling, J.K.  \n",
       "4    3,758,936     Random House      James, E. L.  \n",
       "..         ...              ...               ...  \n",
       "94     808,900            Orion     Binchy, Maeve  \n",
       "95     807,311     Random House    Harris, Robert  \n",
       "96     794,201          Penguin     Oliver, Jamie  \n",
       "97     792,187  Scholastic Ltd.  Collins, Suzanne  \n",
       "98     791,507            Orion      Pelzer, Dave  \n",
       "\n",
       "[99 rows x 5 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.DataFrame({})\n",
    "df[\"Book Name\"] = BookN[0:99]\n",
    "df[\"Author Name\"] = AuthorN[0:99]\n",
    "df[\"Volume Sold\"] = VolumeS[0:99]\n",
    "df[\"Publisher\"] = PublishN[0:99]\n",
    "df[\"Genre\"] = Gen[0:99]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83bda0b",
   "metadata": {},
   "source": [
    "9. Scrape the details most watched tv series of all time from imdb.com.\n",
    "Url = https://www.imdb.com/list/ls095964455/\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time\n",
    "E) Ratings\n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e851944",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH= 'E:\\DataTrained\\chromedriver.exe' #extracting path of the webdriver\n",
    "driver = webdriver.Chrome(PATH)\n",
    "try:\n",
    "    url = \" https://www.imdb.com/list/ls095964455/\"\n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "    \n",
    "except NoSuchElementException :\n",
    "    print(\"No Login page\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e1032a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping Data from the Table \n",
    "\n",
    "TitleName= driver.find_elements_by_xpath('/html/body/div[3]/div/div[2]/div[3]/div[1]/div/div[3]/div[3]/div/div[2]/h3/a')\n",
    "len(TitleName)\n",
    "\n",
    "Titlespan= driver.find_elements_by_xpath('/html/body/div[3]/div/div[2]/div[3]/div[1]/div/div[3]/div[3]/div/div[2]/h3/span[2]')\n",
    "len(Titlespan)\n",
    "\n",
    "\n",
    "TitleGenre= driver.find_elements_by_xpath('/html/body/div[3]/div/div[2]/div[3]/div[1]/div/div[3]/div[3]/div/div[2]/p[1]/span[5]')\n",
    "len(TitleGenre)\n",
    "\n",
    "TitleRuntime= driver.find_elements_by_xpath('/html/body/div[3]/div/div[2]/div[3]/div[1]/div/div[3]/div[3]/div/div[2]/p[1]/span[3]')\n",
    "len(TitleRuntime)\n",
    "\n",
    "\n",
    "TitleRuntime= driver.find_elements_by_xpath('/html/body/div[3]/div/div[2]/div[3]/div[1]/div/div[3]/div[3]/div/div[2]/p[1]/span[3]')\n",
    "len(TitleRuntime)\n",
    "\n",
    "TitleRating= driver.find_elements_by_xpath('/html/body/div[3]/div/div[2]/div[3]/div[1]/div/div[3]/div[3]/div/div/div[1]/div[1]/span[2]')\n",
    "len(TitleRating)\n",
    "\n",
    "TitleVotes= driver.find_elements_by_xpath('/html/body/div[3]/div/div[2]/div[3]/div[1]/div/div[3]/div[3]/div/div[2]/p[4]/span[2]')\n",
    "len(TitleVotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ac4152bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1,981,258',\n",
       " '986,971',\n",
       " '944,184',\n",
       " '282,079',\n",
       " '241,987',\n",
       " '295,402',\n",
       " '138,990',\n",
       " '293,165',\n",
       " '336,546',\n",
       " '425,558',\n",
       " '454,774',\n",
       " '781,465',\n",
       " '514,847',\n",
       " '890,756',\n",
       " '507,548',\n",
       " '163,013',\n",
       " '310,506',\n",
       " '306,930',\n",
       " '1,722,609',\n",
       " '308,015',\n",
       " '428,158',\n",
       " '516,835',\n",
       " '146,572',\n",
       " '142,559',\n",
       " '394,353',\n",
       " '220,232',\n",
       " '404,054',\n",
       " '418,816',\n",
       " '949,101',\n",
       " '661,319',\n",
       " '395,209',\n",
       " '373,480',\n",
       " '131,445',\n",
       " '121,870',\n",
       " '169,549',\n",
       " '151,429',\n",
       " '225,928',\n",
       " '474,117',\n",
       " '208,902',\n",
       " '408,803',\n",
       " '473,052',\n",
       " '60,966',\n",
       " '177,518',\n",
       " '493,827',\n",
       " '353,861',\n",
       " '72,723',\n",
       " '258,663',\n",
       " '229,961',\n",
       " '216,009',\n",
       " '213,512',\n",
       " '225,667',\n",
       " '711,158',\n",
       " '126,387',\n",
       " '326,578',\n",
       " '237,692',\n",
       " '536,155',\n",
       " '483,961',\n",
       " '448,054',\n",
       " '60,292',\n",
       " '108,665',\n",
       " '334,833',\n",
       " '72,343',\n",
       " '102,610',\n",
       " '215,943',\n",
       " '90,218',\n",
       " '88,265',\n",
       " '47,677',\n",
       " '145,382',\n",
       " '359,319',\n",
       " '292,949',\n",
       " '105,330',\n",
       " '202,031',\n",
       " '545,886',\n",
       " '101,844',\n",
       " '125,851',\n",
       " '402,175',\n",
       " '105,307',\n",
       " '219,716',\n",
       " '83,238',\n",
       " '21,114',\n",
       " '132,278',\n",
       " '148,213',\n",
       " '126,996',\n",
       " '35,746',\n",
       " '268,231',\n",
       " '118,716',\n",
       " '127,406',\n",
       " '72,393',\n",
       " '103,307',\n",
       " '188,677',\n",
       " '27,222',\n",
       " '179,361',\n",
       " '190,611',\n",
       " '691,205',\n",
       " '66,426',\n",
       " '48,560',\n",
       " '59,191',\n",
       " '188,887',\n",
       " '40,032',\n",
       " '226,451']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a blank list\n",
    "TitleN=[]\n",
    "for i in TitleName:\n",
    "    TitleN.append(i.text)\n",
    "        \n",
    "\n",
    "TitleN\n",
    "\n",
    "# creating a blank list\n",
    "TitleS=[]\n",
    "for i in Titlespan:\n",
    "    TitleS.append(i.text)\n",
    "        \n",
    "\n",
    "TitleS\n",
    "\n",
    "# creating a blank list\n",
    "TitleG=[]\n",
    "for i in TitleGenre:\n",
    "    TitleG.append(i.text)\n",
    "        \n",
    "\n",
    "TitleG\n",
    "\n",
    "# creating a blank list\n",
    "TitleRT=[]\n",
    "for i in TitleRuntime:\n",
    "    TitleRT.append(i.text)\n",
    "        \n",
    "\n",
    "TitleRT\n",
    "\n",
    "# creating a blank list\n",
    "TitleR=[]\n",
    "for i in TitleRating:\n",
    "    TitleR.append(i.text)\n",
    "        \n",
    "\n",
    "TitleR\n",
    "\n",
    "# creating a blank list\n",
    "TitleV=[]\n",
    "for i in TitleVotes:\n",
    "    TitleV.append(i.text)\n",
    "        \n",
    "\n",
    "TitleV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b80eb509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>1,981,258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016– )</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>986,971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.2</td>\n",
       "      <td>944,184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>282,079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>241,987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Name    Year span                     Genre Run time Ratings  \\\n",
       "0   Game of Thrones  (2011–2019)  Action, Adventure, Drama   57 min     9.2   \n",
       "1   Stranger Things     (2016– )    Drama, Fantasy, Horror   51 min     8.7   \n",
       "2  The Walking Dead  (2010–2022)   Drama, Horror, Thriller   44 min     8.2   \n",
       "3    13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   60 min     7.5   \n",
       "4           The 100  (2014–2020)    Drama, Mystery, Sci-Fi   43 min     7.6   \n",
       "\n",
       "       Votes  \n",
       "0  1,981,258  \n",
       "1    986,971  \n",
       "2    944,184  \n",
       "3    282,079  \n",
       "4    241,987  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making a data frame with the details \n",
    "#A) Name B) Year span C) Genre D) Run time E) Ratings F) Votes\n",
    "\n",
    "df = pd.DataFrame({})\n",
    "\n",
    "\n",
    "df[\"Name\"]= TitleN\n",
    "\n",
    "df[\"Year span\"]= TitleS\n",
    "\n",
    "df[\"Genre\"]= TitleG\n",
    "\n",
    "df[\"Run time\"]= TitleRT\n",
    "\n",
    "df[\"Ratings\"]= TitleR\n",
    "\n",
    "df[\"Votes\"]= TitleV\n",
    "\n",
    "df.head(5)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fead487f",
   "metadata": {},
   "source": [
    "10. Details of Datasets from UCI machine learning repositories.\n",
    "Url = https://archive.ics.uci.edu/\n",
    "You have to find the following details:\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute\n",
    "G) Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0169e27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activating the chrome browser\n",
    "\n",
    "PATH = 'E:\\DataTrained\\chromedriver.exe' #extracting path of the webdriver\n",
    "driver = webdriver.Chrome(PATH)\n",
    "try:\n",
    "    url = \" https://archive.ics.uci.edu/\"\n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "    \n",
    "except NoSuchElementException :\n",
    "    print(\"No Login page\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "794a6e03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DatasetName= driver.find_elements_by_xpath('/html/body/table[3]/tbody/tr/td[2]/table/tbody/tr/td[2]/table/tbody/tr/td[2]/span/a')\n",
    "len(DatasetName)\n",
    "\n",
    "DataType= driver.find_elements_by_xpath('/html/body/table[3]/tbody/tr/td[2]/table/tbody/tr/td[2]/table/tbody/tr/td[2]/span/a')\n",
    "len(DatasetName)\n",
    "\n",
    "\n",
    "/html/body/table/tbody/tr/td/table[2]/tbody/tr[1]/td[2]/p\n",
    "\n",
    "/html/body/table[2]/tbody/tr/td/table[2]/tbody/tr[1]/td[2]/p\n",
    "\n",
    "/html/body/table[2]/tbody/tr/td/table[2]/tbody/tr[1]/td[2]/p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832c6f89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
